{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db851207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:54:32.351578: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-17 18:54:33.198208: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from dataset import LayoutDataset\n",
    "from models import LayoutMLP\n",
    "from scipy.stats import kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aedd7a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:54:36.061006: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 18:54:36.168885: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 18:54:36.169122: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 18:54:36.170884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 18:54:36.171085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 18:54:36.171263: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 18:54:36.867311: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 18:54:36.867528: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 18:54:36.867715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 18:54:36.867865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2103 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train layout:nlp:default 7500 False\n",
      "train layout:nlp:random 7500 False\n",
      "train layout:xla:random 7500 True\n",
      "train layout:xla:default 7500 True\n",
      "test all_filenames 10000 False\n",
      "valid all_filenames 1000 False\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "dataset_take = 7500\n",
    "learning_rate = 1.5e-3\n",
    "batch_per_file_size = 8\n",
    "node_embedding_size = 15\n",
    "layers = [128, 64, 32, 36, 24]\n",
    "\n",
    "dataset = LayoutDataset(\n",
    "    batch_size, dataset_take,\n",
    "    build_tfrecords=False,\n",
    "    batch_per_file_size=batch_per_file_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57227338",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = LayoutMLP(\n",
    "    batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    batch_per_file_size=batch_per_file_size,\n",
    "    node_embedding_size=node_embedding_size,\n",
    "    validation_frequency=10_000,\n",
    "    validations_without_improvement=5,\n",
    "    layer_sizes=layers,\n",
    "    loss='pairwise_hinge',\n",
    "    n_siblings=dataset.n_siblings,\n",
    "    l1_multiplier=2e-8,\n",
    "    output_name='layout_11_17_19_00'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a4de898",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:57:16.035075: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-11-17 18:57:16.094747: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff1b34087b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-17 18:57:16.094800: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2023-11-17 18:57:16.136102: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-17 18:57:16.445644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-11-17 18:57:16.686452: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 500 training loss 3.2600968 lr 0.00007\n",
      "iteration 1000 training loss 2.8857212 lr 0.00015\n",
      "iteration 1500 training loss 2.8137205 lr 0.00022\n",
      "iteration 2000 training loss 2.7070162 lr 0.00030\n",
      "iteration 2500 training loss 2.1701794 lr 0.00037\n",
      "iteration 3000 training loss 1.839183 lr 0.00045\n",
      "iteration 3500 training loss 2.2902656 lr 0.00052\n",
      "iteration 4000 training loss 1.9444615 lr 0.00060\n",
      "iteration 4500 training loss 2.3341267 lr 0.00067\n",
      "iteration 5000 training loss 2.0034542 lr 0.00075\n",
      "iteration 5500 training loss 1.7525834 lr 0.00082\n",
      "iteration 6000 training loss 1.631221 lr 0.00090\n",
      "iteration 6500 training loss 1.6199765 lr 0.00097\n",
      "iteration 7000 training loss 1.8029523 lr 0.00105\n",
      "iteration 7500 training loss 1.5563127 lr 0.00112\n",
      "iteration 8000 training loss 1.2636527 lr 0.00120\n",
      "iteration 8500 training loss 1.201584 lr 0.00127\n",
      "iteration 9000 training loss 1.9085325 lr 0.00135\n",
      "iteration 9500 training loss 1.1794394 lr 0.00142\n",
      "iteration 10000 training loss 1.8645992 lr 0.00150\n",
      "layout:nlp:random 0.8321765156537712\n",
      "layout:nlp:default 0.43174759865036716\n",
      "layout:xla:random 0.57499906545027\n",
      "layout:xla:default 0.27138901667598275\n",
      "epoch 0, it 10000 validation loss -0.528\n",
      "iteration 10500 training loss 1.0317254 lr 0.00150\n",
      "iteration 11000 training loss 1.7580571 lr 0.00150\n",
      "iteration 11500 training loss 1.0698987 lr 0.00150\n",
      "iteration 12000 training loss 1.3973932 lr 0.00150\n",
      "iteration 12500 training loss 1.6092727 lr 0.00150\n",
      "iteration 13000 training loss 1.6929651 lr 0.00150\n",
      "iteration 13500 training loss 1.3207775 lr 0.00150\n",
      "iteration 14000 training loss 1.5938076 lr 0.00150\n",
      "iteration 14500 training loss 1.3887221 lr 0.00150\n",
      "iteration 15000 training loss 2.1358902 lr 0.00150\n",
      "iteration 15500 training loss 1.4513049 lr 0.00150\n",
      "iteration 16000 training loss 1.4049093 lr 0.00150\n",
      "iteration 16500 training loss 0.9752976 lr 0.00150\n",
      "iteration 17000 training loss 1.1931057 lr 0.00150\n",
      "iteration 17500 training loss 1.4969813 lr 0.00150\n",
      "iteration 18000 training loss 1.4687811 lr 0.00150\n",
      "iteration 18500 training loss 1.1479328 lr 0.00150\n",
      "iteration 19000 training loss 1.2236577 lr 0.00150\n",
      "iteration 19500 training loss 1.1291989 lr 0.00149\n",
      "iteration 20000 training loss 1.1017486 lr 0.00149\n",
      "layout:nlp:random 0.9043039759068631\n",
      "layout:nlp:default 0.48236654705188364\n",
      "layout:xla:random 0.6477763977049783\n",
      "layout:xla:default 0.3356059190701175\n",
      "epoch 0, it 20000 validation loss -0.593\n",
      "iteration 20500 training loss 1.4208406 lr 0.00149\n",
      "iteration 21000 training loss 1.493667 lr 0.00149\n",
      "iteration 21500 training loss 0.90558743 lr 0.00149\n",
      "iteration 22000 training loss 1.5947516 lr 0.00149\n",
      "iteration 22500 training loss 1.9057369 lr 0.00149\n",
      "iteration 23000 training loss 1.4797591 lr 0.00149\n",
      "iteration 23500 training loss 1.3327819 lr 0.00149\n",
      "iteration 24000 training loss 1.3780799 lr 0.00149\n",
      "iteration 24500 training loss 0.9220015 lr 0.00149\n",
      "iteration 25000 training loss 1.2630352 lr 0.00149\n",
      "iteration 25500 training loss 1.2895138 lr 0.00149\n",
      "iteration 26000 training loss 1.383229 lr 0.00149\n",
      "iteration 26500 training loss 1.0876619 lr 0.00148\n",
      "iteration 27000 training loss 1.3745639 lr 0.00148\n",
      "iteration 27500 training loss 1.2592475 lr 0.00148\n",
      "iteration 28000 training loss 1.6421127 lr 0.00148\n",
      "iteration 28500 training loss 1.0602238 lr 0.00148\n",
      "iteration 29000 training loss 1.288894 lr 0.00148\n",
      "iteration 29500 training loss 1.6427251 lr 0.00148\n",
      "iteration 30000 training loss 1.2784144 lr 0.00148\n",
      "layout:nlp:random 0.9082602605575076\n",
      "layout:nlp:default 0.47335589938825356\n",
      "layout:xla:random 0.6435074088848415\n",
      "layout:xla:default 0.36229222769019637\n",
      "epoch 0, it 30000 validation loss -0.597\n",
      "iteration 30500 training loss 1.219454 lr 0.00148\n",
      "iteration 31000 training loss 0.8084045 lr 0.00148\n",
      "iteration 31500 training loss 0.9187667 lr 0.00147\n",
      "iteration 32000 training loss 1.1139548 lr 0.00147\n",
      "iteration 32500 training loss 0.9407825 lr 0.00147\n",
      "iteration 33000 training loss 1.3842068 lr 0.00147\n",
      "iteration 33500 training loss 1.0085576 lr 0.00147\n",
      "iteration 34000 training loss 0.96248066 lr 0.00147\n",
      "iteration 34500 training loss 1.1371647 lr 0.00147\n",
      "iteration 35000 training loss 0.9934109 lr 0.00147\n",
      "iteration 35500 training loss 1.1115382 lr 0.00146\n",
      "iteration 36000 training loss 1.1908921 lr 0.00146\n",
      "iteration 36500 training loss 1.3388883 lr 0.00146\n",
      "iteration 37000 training loss 1.2156224 lr 0.00146\n",
      "iteration 37500 training loss 0.9710403 lr 0.00146\n",
      "iteration 38000 training loss 1.1440586 lr 0.00146\n",
      "iteration 38500 training loss 1.13091 lr 0.00145\n",
      "iteration 39000 training loss 0.8626254 lr 0.00145\n",
      "iteration 39500 training loss 1.2114255 lr 0.00145\n",
      "iteration 40000 training loss 0.88557136 lr 0.00145\n",
      "layout:nlp:random 0.9117489766074127\n",
      "layout:nlp:default 0.49128876184833176\n",
      "layout:xla:random 0.6337490507813935\n",
      "layout:xla:default 0.34484055304738875\n",
      "epoch 0, it 40000 validation loss -0.595\n",
      "iteration 40500 training loss 1.5433618 lr 0.00145\n",
      "iteration 41000 training loss 0.79413724 lr 0.00145\n",
      "iteration 41500 training loss 1.3539099 lr 0.00144\n",
      "iteration 42000 training loss 0.7000063 lr 0.00144\n",
      "iteration 42500 training loss 1.0408332 lr 0.00144\n",
      "iteration 43000 training loss 1.2904937 lr 0.00144\n",
      "iteration 43500 training loss 0.97890645 lr 0.00144\n",
      "iteration 44000 training loss 1.2786821 lr 0.00144\n",
      "iteration 44500 training loss 1.1169013 lr 0.00143\n",
      "iteration 45000 training loss 1.5173736 lr 0.00143\n",
      "iteration 45500 training loss 0.95880425 lr 0.00143\n",
      "iteration 46000 training loss 0.9920326 lr 0.00143\n",
      "iteration 46500 training loss 0.55287427 lr 0.00143\n",
      "iteration 47000 training loss 1.2616801 lr 0.00142\n",
      "iteration 47500 training loss 1.0298694 lr 0.00142\n",
      "iteration 48000 training loss 1.1149912 lr 0.00142\n",
      "iteration 48500 training loss 1.3759426 lr 0.00142\n",
      "iteration 49000 training loss 1.3684208 lr 0.00142\n",
      "iteration 49500 training loss 0.8278318 lr 0.00141\n",
      "iteration 50000 training loss 1.1146489 lr 0.00141\n",
      "layout:nlp:random 0.9161757771615667\n",
      "layout:nlp:default 0.48929029234741356\n",
      "layout:xla:random 0.5997673042173612\n",
      "layout:xla:default 0.3480861000826789\n",
      "epoch 0, it 50000 validation loss -0.588\n",
      "iteration 50500 training loss 1.372601 lr 0.00141\n",
      "iteration 51000 training loss 1.2609749 lr 0.00141\n",
      "iteration 51500 training loss 1.0354509 lr 0.00141\n",
      "iteration 52000 training loss 0.811077 lr 0.00140\n",
      "iteration 52500 training loss 1.2864558 lr 0.00140\n",
      "iteration 53000 training loss 0.7536349 lr 0.00140\n",
      "iteration 53500 training loss 1.1065629 lr 0.00140\n",
      "iteration 54000 training loss 0.9180073 lr 0.00139\n",
      "iteration 54500 training loss 1.4129683 lr 0.00139\n",
      "iteration 55000 training loss 0.97468007 lr 0.00139\n",
      "iteration 55500 training loss 1.7530979 lr 0.00139\n",
      "iteration 56000 training loss 0.9766722 lr 0.00138\n",
      "iteration 56500 training loss 0.9640803 lr 0.00138\n",
      "iteration 57000 training loss 1.1718321 lr 0.00138\n",
      "iteration 57500 training loss 1.2736053 lr 0.00138\n",
      "iteration 58000 training loss 1.2275908 lr 0.00137\n",
      "iteration 58500 training loss 1.068513 lr 0.00137\n",
      "iteration 59000 training loss 1.0306275 lr 0.00137\n",
      "iteration 59500 training loss 1.1527506 lr 0.00137\n",
      "iteration 60000 training loss 1.1177711 lr 0.00136\n",
      "layout:nlp:random 0.9304028705745472\n",
      "layout:nlp:default 0.5005581105028173\n",
      "layout:xla:random 0.647110335396261\n",
      "layout:xla:default 0.36922381232741247\n",
      "epoch 0, it 60000 validation loss -0.612\n",
      "iteration 60500 training loss 0.88329315 lr 0.00136\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/kaggle_model_runtime/models.py:90\u001b[0m, in \u001b[0;36mMLP.train\u001b[0;34m(self, dataset, validation_callback)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_stop:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m training_dataset:\n\u001b[0;32m---> 90\u001b[0m         training_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m         iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m iteration \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     93\u001b[0m             \u001b[38;5;66;03m# TODO: use tensorboard -> tune learning rate\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp.train(dataset, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af8041f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layout:nlp:random': 0.9304028705745472,\n",
       " 'layout:nlp:default': 0.5005581105028173,\n",
       " 'layout:xla:random': 0.6477763977049783,\n",
       " 'layout:xla:default': 0.36922381232741247}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.best_val_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc61a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6119902977774387"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(mlp.best_val_subsets.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3418de",
   "metadata": {},
   "source": [
    "## Evaluate validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac0e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = mlp.predict_over_dataset(dataset.valid_data, return_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d9033",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(val_df['target'], bins=50)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.hist(val_df['prediction'], bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded26b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val_df.groupby('ID').apply(lambda x: x.min()).sort_values('prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72249379",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lin = np.linspace(15, 25, 100)\n",
    "#plt.plot(x_lin, x_lin, color='orange')\n",
    "\n",
    "random_sample = val_df.sample(1_000)\n",
    "graph_id = np.random.choice(val_df['ID'].unique())\n",
    "#graph_id = b'layout:xla:default:inception_v3_batch_128_train'\n",
    "#graph_id = b'layout:xla:default:unet_3d.4x4.bf16'\n",
    "random_sample = val_df[val_df['ID'] == graph_id].copy()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(\n",
    "    random_sample.target,\n",
    "    np.clip(random_sample.prediction, a_min=-500.0, a_max=1000.0),\n",
    "    alpha=0.1,\n",
    "    #c=random_sample['ID'].apply(lambda x: x.decode('UTF-8').split(':')[1] == 'xla').values.astype(float)\n",
    ")\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('prediction')\n",
    "plt.title(graph_id)\n",
    "#plt.colorbar()\n",
    "\n",
    "random_sample.sort_values('target', inplace=True)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(\n",
    "    np.arange(len(random_sample)),\n",
    "    np.clip(random_sample.prediction, a_min=-500.0, a_max=1000.0),\n",
    "    alpha=0.1,\n",
    "    #c=random_sample['ID'].apply(lambda x: x.decode('UTF-8').split(':')[1] == 'xla').values.astype(float)\n",
    ")\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('prediction')\n",
    "plt.title(graph_id)\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9767149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mlp.dense_layer_node_1.kernel.numpy().flatten(), bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f3bcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = mlp.embedding_layer_node_ops.weights[0].numpy()\n",
    "emb = emb / np.expand_dims(np.linalg.norm(emb, axis=1), axis=-1)\n",
    "dots = np.matmul(emb, emb.T)\n",
    "plt.imshow(dots)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875ecd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.unravel_index(np.argsort(dots.flatten())[-127], dots.shape)\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37fea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[val_df['ID'] == b'layout:xla:default:unet_3d.4x4.bf16'].sort_values('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae97dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val_batch in dataset.valid_data:\n",
    "    if b'layout:xla:default:mlperf_bert_batch_24_2x2' in val_batch['layout_id'].numpy():\n",
    "        print(val_batch['layout_id'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb4649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(val_batch['layout_id'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c99ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b'layout:xla:default:mlperf_bert_batch_24_2x2' in val_batch['layout_id'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0639b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = val_df.sample(5_000)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(\n",
    "    random_sample['target'],\n",
    "    np.abs(random_sample['target'] - random_sample['prediction']),\n",
    "    alpha=0.07\n",
    ")\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('abs error')\n",
    "x_lin = np.linspace(0, 0.7, 100)\n",
    "#plt.plot(x_lin, x_lin, color='orange')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(\n",
    "    random_sample['target'],\n",
    "    np.square(random_sample['target'] - random_sample['prediction']),\n",
    "    alpha=0.07\n",
    ")\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('squared error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ddb6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_configs(df):\n",
    "    top = df.sort_values('prediction')\n",
    "    top = top['config_index'].values.tolist()\n",
    "    top = [str(i) for i in top]\n",
    "    return ';'.join(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c359b92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_prediction = val_df.groupby('ID').apply(sort_configs)\n",
    "val_prediction.rename(index=lambda x: x.decode('UTF-8'), inplace=True)\n",
    "val_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb521f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd7c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['ID'].map(lambda x: ':'.join(x.decode('UTF-8').split(':')[:3])).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_layout_score_group(df):\n",
    "    score, _ = kendalltau(df['prediction'], df['target'])\n",
    "    return score\n",
    "\n",
    "val_df['subset'] = val_df['ID'].map(lambda x: ':'.join(x.decode('UTF-8').split(':')[:3]))\n",
    "all_means = []\n",
    "for subset in val_df['subset'].unique():\n",
    "    mean = np.mean(val_df[val_df['subset'] == subset].groupby('ID').apply(compute_layout_score_group))\n",
    "    all_means.append(mean)\n",
    "    print(subset, mean)\n",
    "print(np.mean(all_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a3624",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([\n",
    "    0.9235,\n",
    "    0.6591,\n",
    "    0.516,\n",
    "    0.358,\n",
    "    0.968\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3fffb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val_scores = val_df.groupby('ID').apply(compute_layout_score_group)\n",
    "val_scores.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6ed6b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_nodes_list = []\n",
    "for batch in dataset.valid_data:\n",
    "    df = pd.DataFrame(\n",
    "        np.stack([\n",
    "            batch['layout_id'].numpy(), \n",
    "            batch['valid_nodes'].numpy()], axis=-1),\n",
    "        columns=['ID', 'valid_nodes']\n",
    "    ).drop_duplicates('ID')\n",
    "    valid_nodes_list.append(df)\n",
    "valid_nodes = pd.concat(valid_nodes_list).drop_duplicates('ID')\n",
    "valid_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29e14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_nodes.set_index('ID', inplace=True)\n",
    "valid_nodes['scores'] = val_scores\n",
    "valid_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9810f776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_nodes.reset_index(inplace=True)\n",
    "valid_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09650c5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valid_nodes['subset'] = valid_nodes['ID'].apply(lambda x: ':'.join(x.decode('UTF-8').split(':')[:3]))\n",
    "valid_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d15f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    valid_nodes['scores'],\n",
    "    valid_nodes['valid_nodes']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d41b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 'layout:xla:random'\n",
    "valid_nodes_subset = valid_nodes[valid_nodes['subset'] == subset]\n",
    "print(valid_nodes_subset.sort_values('valid_nodes').iloc[-1])\n",
    "plt.scatter(\n",
    "    valid_nodes_subset['scores'],\n",
    "    valid_nodes_subset['valid_nodes']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2718574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layout_score(candidate_order, layout_dict):\n",
    "    runtimes = layout_dict['config_runtime']\n",
    "    best_ranking = np.argsort(runtimes)\n",
    "    assert len(candidate_order) == len(runtimes)\n",
    "    score, _ = kendalltau(candidate_order, best_ranking)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de12cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4289a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_order = np.argsort(layout_dict['config_runtime'])\n",
    "plt.scatter(true_order, candidate_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d439d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "layout_set = 'valid'\n",
    "true_orders = []\n",
    "layout_ids = []\n",
    "for dirpath, dirnames, filenames in os.walk('predict-ai-model-runtime/npz_all/npz/layout'):\n",
    "    if len(filenames) == 0:\n",
    "        continue\n",
    "    \n",
    "    if dirpath.split('/')[-1] != layout_set:\n",
    "        continue\n",
    "        \n",
    "    layout_id_prefix = ':'.join(dirpath.split('/')[-4:-1])\n",
    "    for filename in os.listdir(dirpath):\n",
    "        print(filename)\n",
    "        layout_id = layout_id_prefix+':'+filename[:-4]\n",
    "        layout_dict = dict(np.load(os.path.join(dirpath, filename)))\n",
    "        runtimes = layout_dict['config_runtime']\n",
    "        best_ranking = np.argsort(runtimes)\n",
    "        best_ranking = ';'.join([str(i) for i in best_ranking])\n",
    "        true_orders.append(best_ranking)\n",
    "        layout_ids.append(layout_id)\n",
    "        \n",
    "true_order_df = pd.DataFrame(\n",
    "    data=np.stack([layout_ids, true_orders], axis=-1),\n",
    "    columns=['ID', 'true_order']\n",
    ")\n",
    "true_order_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6177a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layout_id = true_order_df.sample()['ID'].values[0]\n",
    "layout_id = 'layout:xla:default:resnet50.4x4.fp16'\n",
    "true_order = [int(i) for i in true_order_df[true_order_df['ID'] == layout_id]['true_order'].values[0].split(';')]\n",
    "candidate_order = [int(i) for i in val_prediction[layout_id].split(';')]\n",
    "\n",
    "plt.scatter(true_order, candidate_order)\n",
    "plt.xlabel('true order')\n",
    "plt.ylabel('candidate order')\n",
    "plt.title(f'{layout_id}, len {len(true_order)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d506a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_dict = dict(np.load('predict-ai-model-runtime/npz_all/npz/layout/nlp/default/valid/small_bert_bert_en_uncased_L-6_H-256_A-4_batch_size_16_train.npz'))\n",
    "layout_dict['node_config_feat'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039f1d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[val_df['ID'] == b'layout:nlp:default:small_bert_bert_en_uncased_L-6_H-256_A-4_batch_size_16_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c18339",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_result_layout['score'].astype(float).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d434f868",
   "metadata": {},
   "source": [
    "## Inference over test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac93738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = mlp.predict_over_dataset(dataset.test_data, return_labels=False)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39927c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.groupby('ID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ba9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = test_df.groupby('ID').apply(sort_configs)\n",
    "test_prediction.rename(index=lambda x: x.decode('UTF-8'), inplace=True)\n",
    "test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d09fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_prediction, columns=['TopConfigs']).to_csv('predictions/layout_final_test_prediction_11_17_19_00.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9f73f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
