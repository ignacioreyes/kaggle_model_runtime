{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db851207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 19:08:43.995668: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-28 19:08:44.931756: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from dataset import LayoutDataset\n",
    "from models import LayoutMLP\n",
    "from scipy.stats import kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aedd7a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 19:08:47.534124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-28 19:08:47.640908: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-28 19:08:47.641221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-28 19:08:47.643468: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-28 19:08:47.643684: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-28 19:08:47.643876: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-28 19:08:48.361375: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-28 19:08:48.361600: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-28 19:08:48.361793: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-28 19:08:48.361949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2103 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "batch_size = 192\n",
    "learning_rate = 1e-3\n",
    "batch_per_file_size = 8\n",
    "decay_rate = 0.95\n",
    "node_embedding_size = 12\n",
    "layers = [32, 12, 32, 8]\n",
    "\n",
    "dataset = LayoutDataset(\n",
    "    batch_size, train_sample_fraction=1.0,\n",
    "    subset=None, build_tfrecords=False,\n",
    "    batch_per_file_size=batch_per_file_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57227338",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = LayoutMLP(\n",
    "    batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    mask_max_len=dataset.n_config_nodes_upper_limit,\n",
    "    batch_per_file_size=batch_per_file_size,\n",
    "    decay_rate=decay_rate,\n",
    "    node_embedding_size=node_embedding_size,\n",
    "    validation_frequency=10_000,\n",
    "    validations_without_improvement=3,\n",
    "    layer_sizes=layers,\n",
    "    loss='pairwise_hinge',\n",
    "    l1_multiplier=1e-9,\n",
    "    n_siblings=dataset.n_siblings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4de898",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlp.train(dataset, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3418de",
   "metadata": {},
   "source": [
    "## Evaluate validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac0e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = mlp.predict_over_dataset(dataset.valid_data, return_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d9033",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(val_df['target'], bins=50)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.hist(val_df['prediction'], bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded26b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_df.groupby('ID').apply(lambda x: x.min()).sort_values('prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72249379",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lin = np.linspace(15, 25, 100)\n",
    "#plt.plot(x_lin, x_lin, color='orange')\n",
    "\n",
    "random_sample = val_df.sample(1_000)\n",
    "graph_id = np.random.choice(val_df['ID'].unique())\n",
    "#graph_id = b'layout:xla:default:inception_v3_batch_128_train'\n",
    "#graph_id = b'layout:xla:default:unet_3d.4x4.bf16'\n",
    "random_sample = val_df[val_df['ID'] == graph_id].copy()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(\n",
    "    random_sample.target,\n",
    "    np.clip(random_sample.prediction, a_min=-500.0, a_max=1000.0),\n",
    "    alpha=0.1,\n",
    "    #c=random_sample['ID'].apply(lambda x: x.decode('UTF-8').split(':')[1] == 'xla').values.astype(float)\n",
    ")\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('prediction')\n",
    "plt.title(graph_id)\n",
    "#plt.colorbar()\n",
    "\n",
    "random_sample.sort_values('target', inplace=True)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(\n",
    "    np.arange(len(random_sample)),\n",
    "    np.clip(random_sample.prediction, a_min=-500.0, a_max=1000.0),\n",
    "    alpha=0.1,\n",
    "    #c=random_sample['ID'].apply(lambda x: x.decode('UTF-8').split(':')[1] == 'xla').values.astype(float)\n",
    ")\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('prediction')\n",
    "plt.title(graph_id)\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9767149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mlp.k_layer.kernel.numpy().flatten(), bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81f7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "kind = 2\n",
    "plt.subplot(2, 1, 1)\n",
    "k_vals = mlp.k_layer.kernel.numpy().reshape(212, 8, -1)[:, kind, :].T\n",
    "plt.imshow(k_vals)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "q_vals = mlp.q_layer.kernel.numpy().reshape(212, 8, -1)[:, kind, :].T\n",
    "plt.imshow(q_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934d7922",
   "metadata": {},
   "source": [
    "00        interesting features (20)\n",
    "            np.arange(21, 27),  # shape dims\n",
    "            np.arange(31, 37),  # reshape/broadcast dims\n",
    "            np.arange(95, 99),  # conv dims input\n",
    "            np.arange(101, 105),  # conv dims kernel\n",
    "20        parent output shapes (12)\n",
    "32        sibling shapes (n_siblings*6)\n",
    "50        physical layout (6)\n",
    "56        node layout (18)\n",
    "74        parent phys layout (12)\n",
    "86        siblings layout (n_sibling*18)\n",
    "140        parent opcodes (2)\n",
    "164        sibling opcodes (n_siblings)\n",
    "200        opcode (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e781807",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [20, 12, 18, 6, 18, 12, 18*3, 24, 36, 12]\n",
    "np.cumsum(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f3bcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = mlp.embedding_layer_node_ops.weights[0].numpy()\n",
    "emb = emb / np.expand_dims(np.linalg.norm(emb, axis=1), axis=-1)\n",
    "dots = np.matmul(emb, emb.T)\n",
    "plt.imshow(dots)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb03c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dots[34, 26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e7c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(dots[26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875ecd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.unravel_index(np.argsort(dots.flatten())[-122], dots.shape)\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37fea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[val_df['ID'] == b'layout:xla:default:unet_3d.4x4.bf16'].sort_values('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae97dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val_batch in dataset.valid_data:\n",
    "    if b'layout:xla:default:mlperf_bert_batch_24_2x2' in val_batch['layout_id'].numpy():\n",
    "        print(val_batch['layout_id'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb4649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(val_batch['layout_id'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c99ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b'layout:xla:default:mlperf_bert_batch_24_2x2' in val_batch['layout_id'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b59b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_ids = val_batch['layout_id']\n",
    "config_descriptor = val_batch['node_descriptor']\n",
    "valid_mask = val_batch['valid_nodes']\n",
    "graph_descriptor = val_batch['graph_descriptor']\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    subset_info_str = tf.map_fn(\n",
    "        lambda layout_id: tf.strings.reduce_join(\n",
    "            tf.strings.split(layout_id, \":\")[:3]),\n",
    "        layout_ids\n",
    "    )\n",
    "\n",
    "subset_info = mlp.text_vectorization(subset_info_str)\n",
    "subset_info = tf.expand_dims(subset_info, axis=-1)\n",
    "subset_info = mlp.embedding_layer_subset_info(subset_info)\n",
    "subset_info = subset_info[:, 0, :]\n",
    "\n",
    "# for si, sn in zip(subset_info_str.numpy(), subset_info.numpy()):\n",
    "#     print(si, sn)\n",
    "\n",
    "node_operations = config_descriptor[:, :, -1]\n",
    "config_descriptor = config_descriptor[:, :, :-1]\n",
    "node_operations = tf.cast(node_operations, tf.int32)\n",
    "# node_operations.shape == (batch_size, mask_max_len)                                                                                                                                 \n",
    "node_embedding = mlp.embedding_layer_node_ops(node_operations)\n",
    "# node_embedding.shape == (batch_size, mask_max_len, embed_len)\n",
    "# np.unique(node_operations.numpy().flatten(), return_counts=True)\n",
    "\n",
    "x = mlp.normalization_layer_config_nodes(config_descriptor)\n",
    "normal_graph_descriptor = mlp.normalization_layer_graph_descriptor(graph_descriptor)\n",
    "x = tf.concat([x, node_embedding], axis=-1)\n",
    "\n",
    "x = mlp.dense_layer_node_1(x)\n",
    "x = mlp.relu_layer(x)  # (batch_size, n_config_nodes_upper_limit, n_units)                                                                                                           \n",
    "x = mlp.dense_layer_node_2(x)\n",
    "x = mlp.relu_layer(x)  # (batch_size, n_config_nodes_upper_limit, n_units)                                                                                                           \n",
    "\n",
    "# plt.hist(x.numpy().flatten(), bins=100);\n",
    "float_mask = tf.sequence_mask(valid_mask, mlp.mask_max_len, dtype=tf.float32)\n",
    "# (batch_size, n_config_nodes_upper_limit)                                                                                                                                            \n",
    "\n",
    "float_mask = tf.expand_dims(float_mask, axis=-1)\n",
    "x = x * float_mask\n",
    "\n",
    "x = tf.reduce_sum(x, axis=1)\n",
    "#plt.subplot(2, 1, 1)\n",
    "#plt.hist(x.numpy().flatten(), bins=100);\n",
    "\n",
    "x = x / tf.expand_dims(tf.cast(valid_mask, tf.float32), axis=-1)\n",
    "#plt.subplot(2, 1, 2)\n",
    "#plt.hist(x.numpy().flatten(), bins=100);\n",
    "for i, lid, gd, nd in zip(range(96), layout_ids.numpy(), graph_descriptor.numpy(), normal_graph_descriptor.numpy()):\n",
    "    if i in [19]:\n",
    "        print(i, gd[80:90], nd[80:90], lid)\n",
    "x = tf.concat([x, normal_graph_descriptor, subset_info], axis=-1)\n",
    "#plt.hist(x.numpy().flatten(), bins=100);\n",
    "x = mlp.dense_layer_global_1(x)\n",
    "x = mlp.relu_layer(x)\n",
    "#plt.hist(x.numpy().flatten(), bins=100);\n",
    "x = mlp.dense_layer_global_2(x)\n",
    "x = mlp.relu_layer(x)\n",
    "#plt.hist(x.numpy().flatten(), bins=100);\n",
    "x = mlp.dense_layer_global_3(x)\n",
    "x = tf.reshape(x, (-1,))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0639b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = val_df.sample(5_000)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(\n",
    "    random_sample['target'],\n",
    "    np.abs(random_sample['target'] - random_sample['prediction']),\n",
    "    alpha=0.07\n",
    ")\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('abs error')\n",
    "x_lin = np.linspace(0, 0.7, 100)\n",
    "#plt.plot(x_lin, x_lin, color='orange')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(\n",
    "    random_sample['target'],\n",
    "    np.square(random_sample['target'] - random_sample['prediction']),\n",
    "    alpha=0.07\n",
    ")\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('squared error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c359b92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sort_configs(df):\n",
    "    top = df.sort_values('prediction')\n",
    "    top = top['config_index'].values.tolist()\n",
    "    top = [str(i) for i in top]\n",
    "    return ';'.join(top)\n",
    "\n",
    "val_prediction = val_df.groupby('ID').apply(sort_configs)\n",
    "val_prediction.rename(index=lambda x: x.decode('UTF-8'), inplace=True)\n",
    "val_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb521f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd7c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['ID'].map(lambda x: ':'.join(x.decode('UTF-8').split(':')[:3])).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_layout_score_group(df):\n",
    "    score, _ = kendalltau(df['prediction'], df['target'])\n",
    "    return score\n",
    "\n",
    "val_df['subset'] = val_df['ID'].map(lambda x: ':'.join(x.decode('UTF-8').split(':')[:3]))\n",
    "for subset in val_df['subset'].unique():\n",
    "    mean = np.mean(val_df[val_df['subset'] == subset].groupby('ID').apply(compute_layout_score_group))\n",
    "    print(subset, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([0.4185, 0.8167, 0.538, 0.2525])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3fffb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val_scores = val_df.groupby('ID').apply(compute_layout_score_group)\n",
    "val_scores.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2718574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layout_score(candidate_order, layout_dict):\n",
    "    runtimes = layout_dict['config_runtime']\n",
    "    best_ranking = np.argsort(runtimes)\n",
    "    assert len(candidate_order) == len(runtimes)\n",
    "    score, _ = kendalltau(candidate_order, best_ranking)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de12cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4289a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_order = np.argsort(layout_dict['config_runtime'])\n",
    "plt.scatter(true_order, candidate_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d439d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "layout_set = 'valid'\n",
    "true_orders = []\n",
    "layout_ids = []\n",
    "for dirpath, dirnames, filenames in os.walk('predict-ai-model-runtime/npz_all/npz/layout'):\n",
    "    if len(filenames) == 0:\n",
    "        continue\n",
    "    \n",
    "    if dirpath.split('/')[-1] != layout_set:\n",
    "        continue\n",
    "        \n",
    "    layout_id_prefix = ':'.join(dirpath.split('/')[-4:-1])\n",
    "    for filename in os.listdir(dirpath):\n",
    "        print(filename)\n",
    "        layout_id = layout_id_prefix+':'+filename[:-4]\n",
    "        layout_dict = dict(np.load(os.path.join(dirpath, filename)))\n",
    "        runtimes = layout_dict['config_runtime']\n",
    "        best_ranking = np.argsort(runtimes)\n",
    "        best_ranking = ';'.join([str(i) for i in best_ranking])\n",
    "        true_orders.append(best_ranking)\n",
    "        layout_ids.append(layout_id)\n",
    "        \n",
    "true_order_df = pd.DataFrame(\n",
    "    data=np.stack([layout_ids, true_orders], axis=-1),\n",
    "    columns=['ID', 'true_order']\n",
    ")\n",
    "true_order_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6177a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layout_id = true_order_df.sample()['ID'].values[0]\n",
    "layout_id = 'layout:xla:default:resnet50.4x4.fp16'\n",
    "true_order = [int(i) for i in true_order_df[true_order_df['ID'] == layout_id]['true_order'].values[0].split(';')]\n",
    "candidate_order = [int(i) for i in val_prediction[layout_id].split(';')]\n",
    "\n",
    "plt.scatter(true_order, candidate_order)\n",
    "plt.xlabel('true order')\n",
    "plt.ylabel('candidate order')\n",
    "plt.title(f'{layout_id}, len {len(true_order)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d506a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_dict = dict(np.load('predict-ai-model-runtime/npz_all/npz/layout/nlp/default/valid/small_bert_bert_en_uncased_L-6_H-256_A-4_batch_size_16_train.npz'))\n",
    "layout_dict['node_config_feat'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039f1d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[val_df['ID'] == b'layout:nlp:default:small_bert_bert_en_uncased_L-6_H-256_A-4_batch_size_16_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c18339",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_result_layout['score'].astype(float).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d434f868",
   "metadata": {},
   "source": [
    "## Inference over test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac93738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = mlp.predict_over_dataset(dataset.test_data, return_labels=False)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ba9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = test_df.groupby('ID').apply(sort_configs)\n",
    "test_prediction.rename(index=lambda x: x.decode('UTF-8'), inplace=True)\n",
    "test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d09fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_prediction, columns=['TopConfigs']).to_csv('layout_none_test_prediction_10_21_08_08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4511f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.abs(mlp.dense_layer_1.kernel.numpy().flatten()), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9f73f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
